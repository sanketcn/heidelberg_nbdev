---

title: Title


keywords: fastai
sidebar: home_sidebar



nb_path: "unit_test.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: unit_test.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install pydeequ
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: pydeequ in /opt/conda/lib/python3.7/site-packages (0.1.5)
Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from pydeequ) (1.0.1)
Requirement already satisfied: pyspark==2.4.7 in /opt/conda/lib/python3.7/site-packages (from pydeequ) (2.4.7)
Requirement already satisfied: python-dateutil&gt;=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas-&gt;pydeequ) (2.8.1)
Requirement already satisfied: pytz&gt;=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas-&gt;pydeequ) (2019.3)
Requirement already satisfied: numpy&gt;=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas-&gt;pydeequ) (1.18.1)
Requirement already satisfied: py4j==0.10.7 in /opt/conda/lib/python3.7/site-packages (from pyspark==2.4.7-&gt;pydeequ) (0.10.7)
Requirement already satisfied: six&gt;=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil&gt;=2.6.1-&gt;pandas-&gt;pydeequ) (1.14.0)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span><span class="p">,</span> <span class="n">Row</span>
<span class="kn">import</span> <span class="nn">pydeequ</span>

<span class="n">spark</span> <span class="o">=</span> <span class="p">(</span><span class="n">SparkSession</span>
    <span class="o">.</span><span class="n">builder</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.jars.packages&quot;</span><span class="p">,</span> <span class="n">pydeequ</span><span class="o">.</span><span class="n">deequ_maven_coord</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.jars.excludes&quot;</span><span class="p">,</span> <span class="n">pydeequ</span><span class="o">.</span><span class="n">f2j_maven_coord</span><span class="p">)</span>
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">())</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span>
            <span class="n">Row</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="s2">&quot;foo&quot;</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
            <span class="n">Row</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">6</span><span class="p">),</span>
            <span class="n">Row</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="s2">&quot;baz&quot;</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="kc">None</span><span class="p">)])</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">Exception</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-3-7e79db3456fc&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span>     <span class="ansi-blue-fg">.</span>builder
<span class="ansi-green-intense-fg ansi-bold">      6</span>     <span class="ansi-blue-fg">.</span>config<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;spark.jars.packages&#34;</span><span class="ansi-blue-fg">,</span> pydeequ<span class="ansi-blue-fg">.</span>deequ_maven_coord<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">----&gt; 7</span><span class="ansi-red-fg">     </span><span class="ansi-blue-fg">.</span>config<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;spark.jars.excludes&#34;</span><span class="ansi-blue-fg">,</span> pydeequ<span class="ansi-blue-fg">.</span>f2j_maven_coord<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      8</span>     .getOrCreate())
<span class="ansi-green-intense-fg ansi-bold">      9</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/pyspark/sql/session.py</span> in <span class="ansi-cyan-fg">getOrCreate</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    171</span>                     <span class="ansi-green-fg">for</span> key<span class="ansi-blue-fg">,</span> value <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>_options<span class="ansi-blue-fg">.</span>items<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    172</span>                         sparkConf<span class="ansi-blue-fg">.</span>set<span class="ansi-blue-fg">(</span>key<span class="ansi-blue-fg">,</span> value<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 173</span><span class="ansi-red-fg">                     </span>sc <span class="ansi-blue-fg">=</span> SparkContext<span class="ansi-blue-fg">.</span>getOrCreate<span class="ansi-blue-fg">(</span>sparkConf<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    174</span>                     <span class="ansi-red-fg"># This SparkContext may be an existing one.</span>
<span class="ansi-green-intense-fg ansi-bold">    175</span>                     <span class="ansi-green-fg">for</span> key<span class="ansi-blue-fg">,</span> value <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>_options<span class="ansi-blue-fg">.</span>items<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/pyspark/context.py</span> in <span class="ansi-cyan-fg">getOrCreate</span><span class="ansi-blue-fg">(cls, conf)</span>
<span class="ansi-green-intense-fg ansi-bold">    365</span>         <span class="ansi-green-fg">with</span> SparkContext<span class="ansi-blue-fg">.</span>_lock<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    366</span>             <span class="ansi-green-fg">if</span> SparkContext<span class="ansi-blue-fg">.</span>_active_spark_context <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 367</span><span class="ansi-red-fg">                 </span>SparkContext<span class="ansi-blue-fg">(</span>conf<span class="ansi-blue-fg">=</span>conf <span class="ansi-green-fg">or</span> SparkConf<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    368</span>             <span class="ansi-green-fg">return</span> SparkContext<span class="ansi-blue-fg">.</span>_active_spark_context
<span class="ansi-green-intense-fg ansi-bold">    369</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/pyspark/context.py</span> in <span class="ansi-cyan-fg">__init__</span><span class="ansi-blue-fg">(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)</span>
<span class="ansi-green-intense-fg ansi-bold">    131</span>                     &#34; note this option will be removed in Spark 3.0&#34;)
<span class="ansi-green-intense-fg ansi-bold">    132</span> 
<span class="ansi-green-fg">--&gt; 133</span><span class="ansi-red-fg">         </span>SparkContext<span class="ansi-blue-fg">.</span>_ensure_initialized<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> gateway<span class="ansi-blue-fg">=</span>gateway<span class="ansi-blue-fg">,</span> conf<span class="ansi-blue-fg">=</span>conf<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    134</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    135</span>             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/pyspark/context.py</span> in <span class="ansi-cyan-fg">_ensure_initialized</span><span class="ansi-blue-fg">(cls, instance, gateway, conf)</span>
<span class="ansi-green-intense-fg ansi-bold">    314</span>         <span class="ansi-green-fg">with</span> SparkContext<span class="ansi-blue-fg">.</span>_lock<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    315</span>             <span class="ansi-green-fg">if</span> <span class="ansi-green-fg">not</span> SparkContext<span class="ansi-blue-fg">.</span>_gateway<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 316</span><span class="ansi-red-fg">                 </span>SparkContext<span class="ansi-blue-fg">.</span>_gateway <span class="ansi-blue-fg">=</span> gateway <span class="ansi-green-fg">or</span> launch_gateway<span class="ansi-blue-fg">(</span>conf<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    317</span>                 SparkContext<span class="ansi-blue-fg">.</span>_jvm <span class="ansi-blue-fg">=</span> SparkContext<span class="ansi-blue-fg">.</span>_gateway<span class="ansi-blue-fg">.</span>jvm
<span class="ansi-green-intense-fg ansi-bold">    318</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/pyspark/java_gateway.py</span> in <span class="ansi-cyan-fg">launch_gateway</span><span class="ansi-blue-fg">(conf)</span>
<span class="ansi-green-intense-fg ansi-bold">     44</span>     <span class="ansi-blue-fg">:</span><span class="ansi-green-fg">return</span><span class="ansi-blue-fg">:</span> a JVM gateway
<span class="ansi-green-intense-fg ansi-bold">     45</span>     &#34;&#34;&#34;
<span class="ansi-green-fg">---&gt; 46</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> _launch_gateway<span class="ansi-blue-fg">(</span>conf<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     47</span> 
<span class="ansi-green-intense-fg ansi-bold">     48</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/pyspark/java_gateway.py</span> in <span class="ansi-cyan-fg">_launch_gateway</span><span class="ansi-blue-fg">(conf, insecure)</span>
<span class="ansi-green-intense-fg ansi-bold">    106</span> 
<span class="ansi-green-intense-fg ansi-bold">    107</span>             <span class="ansi-green-fg">if</span> <span class="ansi-green-fg">not</span> os<span class="ansi-blue-fg">.</span>path<span class="ansi-blue-fg">.</span>isfile<span class="ansi-blue-fg">(</span>conn_info_file<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 108</span><span class="ansi-red-fg">                 </span><span class="ansi-green-fg">raise</span> Exception<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Java gateway process exited before sending its port number&#34;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    109</span> 
<span class="ansi-green-intense-fg ansi-bold">    110</span>             <span class="ansi-green-fg">with</span> open<span class="ansi-blue-fg">(</span>conn_info_file<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#34;rb&#34;</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">as</span> info<span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">Exception</span>: Java gateway process exited before sending its port number</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span><span class="nb">unset</span> PYSPARK_SUBMIT_ARGS 
<span class="n">setenv</span> <span class="n">SPARK_HOME</span> <span class="s2">&quot;home&quot;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-cyan-fg">  File </span><span class="ansi-green-fg">&#34;&lt;ipython-input-19-6337bb741df8&gt;&#34;</span><span class="ansi-cyan-fg">, line </span><span class="ansi-green-fg">2</span>
<span class="ansi-red-fg">    setenv SPARK_HOME &#34;home&#34;</span>
                    ^
<span class="ansi-red-fg">SyntaxError</span><span class="ansi-red-fg">:</span> invalid syntax
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;PYSPARK_SUBMIT_ARGS&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;--master mymaster --total-executor 2 --conf &#39;spark.driver.extraJavaOptions= -Dhttp.proxyHost=proxy.mycorp.com-Dhttp.proxyPort=1234 -Dhttp.nonProxyHosts=localhost|.mycorp.com|127.0.0.1 -Dhttps.proxyHost=proxy.mycorp.com -Dhttps.proxyPort=1234 -Dhttps.nonProxyHosts=localhost|.mycorp.com|127.0.0.1 pyspark-shell&#39;&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sagemaker_pyspark</span>
<span class="kn">import</span> <span class="nn">pydeequ</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="n">classpath</span> <span class="o">=</span> <span class="s2">&quot;:&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sagemaker_pyspark</span><span class="o">.</span><span class="n">classpath_jars</span><span class="p">())</span> 
<span class="n">spark</span> <span class="o">=</span> <span class="p">(</span><span class="n">SparkSession</span> <span class="o">.</span><span class="n">builder</span> <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.driver.extraClassPath&quot;</span><span class="p">,</span> <span class="n">classpath</span><span class="p">)</span> <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.jars.packages&quot;</span><span class="p">,</span> <span class="n">pydeequ</span><span class="o">.</span><span class="n">deequ_maven_coord</span><span class="p">)</span> <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.jars.excludes&quot;</span><span class="p">,</span> <span class="n">pydeequ</span><span class="o">.</span><span class="n">f2j_maven_coord</span><span class="p">)</span> <span class="o">.</span><span class="n">getOrCreate</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">Exception</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-25-cfdf61cfea95&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> <span class="ansi-green-fg">from</span> pyspark<span class="ansi-blue-fg">.</span>sql <span class="ansi-green-fg">import</span> SparkSession
<span class="ansi-green-intense-fg ansi-bold">      4</span> classpath <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">&#34;:&#34;</span><span class="ansi-blue-fg">.</span>join<span class="ansi-blue-fg">(</span>sagemaker_pyspark<span class="ansi-blue-fg">.</span>classpath_jars<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">----&gt; 5</span><span class="ansi-red-fg"> </span>spark <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span>SparkSession <span class="ansi-blue-fg">.</span>builder <span class="ansi-blue-fg">.</span>config<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;spark.driver.extraClassPath&#34;</span><span class="ansi-blue-fg">,</span> classpath<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">.</span>config<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;spark.jars.packages&#34;</span><span class="ansi-blue-fg">,</span> pydeequ<span class="ansi-blue-fg">.</span>deequ_maven_coord<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">.</span>config<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;spark.jars.excludes&#34;</span><span class="ansi-blue-fg">,</span> pydeequ<span class="ansi-blue-fg">.</span>f2j_maven_coord<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">.</span>getOrCreate<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/pyspark/sql/session.py</span> in <span class="ansi-cyan-fg">getOrCreate</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    171</span>                     <span class="ansi-green-fg">for</span> key<span class="ansi-blue-fg">,</span> value <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>_options<span class="ansi-blue-fg">.</span>items<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    172</span>                         sparkConf<span class="ansi-blue-fg">.</span>set<span class="ansi-blue-fg">(</span>key<span class="ansi-blue-fg">,</span> value<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 173</span><span class="ansi-red-fg">                     </span>sc <span class="ansi-blue-fg">=</span> SparkContext<span class="ansi-blue-fg">.</span>getOrCreate<span class="ansi-blue-fg">(</span>sparkConf<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    174</span>                     <span class="ansi-red-fg"># This SparkContext may be an existing one.</span>
<span class="ansi-green-intense-fg ansi-bold">    175</span>                     <span class="ansi-green-fg">for</span> key<span class="ansi-blue-fg">,</span> value <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>_options<span class="ansi-blue-fg">.</span>items<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/pyspark/context.py</span> in <span class="ansi-cyan-fg">getOrCreate</span><span class="ansi-blue-fg">(cls, conf)</span>
<span class="ansi-green-intense-fg ansi-bold">    365</span>         <span class="ansi-green-fg">with</span> SparkContext<span class="ansi-blue-fg">.</span>_lock<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    366</span>             <span class="ansi-green-fg">if</span> SparkContext<span class="ansi-blue-fg">.</span>_active_spark_context <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 367</span><span class="ansi-red-fg">                 </span>SparkContext<span class="ansi-blue-fg">(</span>conf<span class="ansi-blue-fg">=</span>conf <span class="ansi-green-fg">or</span> SparkConf<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    368</span>             <span class="ansi-green-fg">return</span> SparkContext<span class="ansi-blue-fg">.</span>_active_spark_context
<span class="ansi-green-intense-fg ansi-bold">    369</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/pyspark/context.py</span> in <span class="ansi-cyan-fg">__init__</span><span class="ansi-blue-fg">(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)</span>
<span class="ansi-green-intense-fg ansi-bold">    131</span>                     &#34; note this option will be removed in Spark 3.0&#34;)
<span class="ansi-green-intense-fg ansi-bold">    132</span> 
<span class="ansi-green-fg">--&gt; 133</span><span class="ansi-red-fg">         </span>SparkContext<span class="ansi-blue-fg">.</span>_ensure_initialized<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> gateway<span class="ansi-blue-fg">=</span>gateway<span class="ansi-blue-fg">,</span> conf<span class="ansi-blue-fg">=</span>conf<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    134</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    135</span>             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/pyspark/context.py</span> in <span class="ansi-cyan-fg">_ensure_initialized</span><span class="ansi-blue-fg">(cls, instance, gateway, conf)</span>
<span class="ansi-green-intense-fg ansi-bold">    314</span>         <span class="ansi-green-fg">with</span> SparkContext<span class="ansi-blue-fg">.</span>_lock<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    315</span>             <span class="ansi-green-fg">if</span> <span class="ansi-green-fg">not</span> SparkContext<span class="ansi-blue-fg">.</span>_gateway<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 316</span><span class="ansi-red-fg">                 </span>SparkContext<span class="ansi-blue-fg">.</span>_gateway <span class="ansi-blue-fg">=</span> gateway <span class="ansi-green-fg">or</span> launch_gateway<span class="ansi-blue-fg">(</span>conf<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    317</span>                 SparkContext<span class="ansi-blue-fg">.</span>_jvm <span class="ansi-blue-fg">=</span> SparkContext<span class="ansi-blue-fg">.</span>_gateway<span class="ansi-blue-fg">.</span>jvm
<span class="ansi-green-intense-fg ansi-bold">    318</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/pyspark/java_gateway.py</span> in <span class="ansi-cyan-fg">launch_gateway</span><span class="ansi-blue-fg">(conf)</span>
<span class="ansi-green-intense-fg ansi-bold">     44</span>     <span class="ansi-blue-fg">:</span><span class="ansi-green-fg">return</span><span class="ansi-blue-fg">:</span> a JVM gateway
<span class="ansi-green-intense-fg ansi-bold">     45</span>     &#34;&#34;&#34;
<span class="ansi-green-fg">---&gt; 46</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> _launch_gateway<span class="ansi-blue-fg">(</span>conf<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     47</span> 
<span class="ansi-green-intense-fg ansi-bold">     48</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/pyspark/java_gateway.py</span> in <span class="ansi-cyan-fg">_launch_gateway</span><span class="ansi-blue-fg">(conf, insecure)</span>
<span class="ansi-green-intense-fg ansi-bold">    106</span> 
<span class="ansi-green-intense-fg ansi-bold">    107</span>             <span class="ansi-green-fg">if</span> <span class="ansi-green-fg">not</span> os<span class="ansi-blue-fg">.</span>path<span class="ansi-blue-fg">.</span>isfile<span class="ansi-blue-fg">(</span>conn_info_file<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 108</span><span class="ansi-red-fg">                 </span><span class="ansi-green-fg">raise</span> Exception<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Java gateway process exited before sending its port number&#34;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    109</span> 
<span class="ansi-green-intense-fg ansi-bold">    110</span>             <span class="ansi-green-fg">with</span> open<span class="ansi-blue-fg">(</span>conn_info_file<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#34;rb&#34;</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">as</span> info<span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">Exception</span>: Java gateway process exited before sending its port number</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;s3a://amazon-reviews-pds/parquet/product_category=Electronics/&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-3-e8fa7e50a97e&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>df <span class="ansi-blue-fg">=</span> spark<span class="ansi-blue-fg">.</span>read<span class="ansi-blue-fg">.</span>parquet<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;s3a://amazon-reviews-pds/parquet/product_category=Electronics/&#34;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">NameError</span>: name &#39;spark&#39; is not defined</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sagemaker_pyspark</span>
<span class="kn">import</span> <span class="nn">pydeequ</span>

<span class="n">classpath</span> <span class="o">=</span> <span class="s2">&quot;:&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sagemaker_pyspark</span><span class="o">.</span><span class="n">classpath_jars</span><span class="p">())</span>

<span class="n">spark</span> <span class="o">=</span> <span class="p">(</span><span class="n">SparkSession</span>
    <span class="o">.</span><span class="n">builder</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.driver.extraClassPath&quot;</span><span class="p">,</span> <span class="n">classpath</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.jars.packages&quot;</span><span class="p">,</span> <span class="n">pydeequ</span><span class="o">.</span><span class="n">deequ_maven_coord</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.jars.excludes&quot;</span><span class="p">,</span> <span class="n">pydeequ</span><span class="o">.</span><span class="n">f2j_maven_coord</span><span class="p">)</span>
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>The code failed because of a fatal error:
	Error sending http request and maximum retry encountered..

Some things to try:
a) Make sure Spark has enough available resources for Jupyter to create a Spark context.
b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.
c) Restart the kernel.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

